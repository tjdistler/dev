{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002f5b32-5acc-4be6-961d-8cef3d8cfb39",
   "metadata": {},
   "source": [
    "# The spelled-out intro to language modeling: building makemore\n",
    "\n",
    "[Andrej Karpathy](https://karpathy.ai/)\n",
    "\n",
    "[YouTube video link](https://youtu.be/PaCmpygFfXo?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n",
    "\n",
    "> We implement a bigram character-level language model, which we will further complexify in followup videos into a modern Transformer language model, like GPT. In this video, the focus is on (1) introducing torch.Tensor and its subtleties and use in efficiently evaluating neural networks and (2) the overall framework of language modeling that includes model training, sampling, and the evaluation of a loss (e.g. the negative log likelihood for classification).\n",
    "\n",
    "https://github.com/karpathy/makemore\n",
    "\n",
    "Requires the training file: `names.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d36877-d59f-4d49-b893-f160b5c12061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run ONCE to update any new kernel instance.\n",
    "# You MUST restart the kernel after updating.\n",
    "!pip install --upgrade pip\n",
    "!pip install graphviz\n",
    "!apt-get update\n",
    "!apt-get install -y graphviz\n",
    "!pip install torch\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b465f21-30e6-42f4-9e58-67daa7383483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a2206-84a8-428b-949e-4e4a2016ada6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa9697-73f9-4383-96ba-3ade48a09920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c2743-b77b-446f-9a4b-60c2b243bc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a12bf-6f12-4268-a4dc-4f233eeb7647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344432cd-e450-4ece-93e5-533737108036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = {} # store bigram counts in a dictionary\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1,ch2 in zip(chs, chs[1:]): # build a list of bigram pairs (sequential characters)\n",
    "        bigram = (ch1, ch2)\n",
    "        b[bigram] = b.get(bigram, 0) + 1\n",
    "        #print(ch1, ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c92742-cef8-4d9a-a4fd-79379554b237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted(b.items(), key = lambda kv: -kv[1]) # sort (reversed) by the second element in the tuples (i.e. the counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620e933-2675-4a0e-85ae-2c197d62fa64",
   "metadata": {},
   "source": [
    "## Represent the training set as a 2D array\n",
    "This will tell us the number of times character X is followed by character Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f8976-5270-457b-8baa-61e84e15efb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b4089-1f15-4bab-a141-9bf26fe65116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf996520-32b5-43e2-b797-f05006f58d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs, chs[1:]): # build a list of bigram pairs (sequential characters)\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38747ea0-2fac-43d2-8737-46fa0d19b4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha='center', va='bottom', color='gray')\n",
    "        plt.text(j, i, N[i,j].item(), ha='center', va='top', color='gray')\n",
    "plt.title('X is followed by Y N-times')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905d3f5-1b6f-4f03-8f68-fc5ff4ded8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N[0] # grab first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed9030-1193-426c-90b9-fecbb28e8978",
   "metadata": {},
   "source": [
    "## Sample data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a632ff0-9206-4a22-a5fb-4f328c091add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build probability data set\n",
    "p = N[0].float()\n",
    "p = p / p.sum() # normalize to 1.0\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e9aab-f442-483e-9559-28180d375ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cec3d3-449b-460c-949b-b1d3d38f0b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We use a generator to make the random distribution repeatable.\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "p = torch.rand(3, generator=g)\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47cde04-41f0-4e58-a509-0aeaa32b5a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multinomial() takes a probability distribution and pulls samples out according to that distribution (with replacement).\n",
    "torch.multinomial(p, num_samples=100, replacement=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ab9fd-3f93-41d5-956c-e179adf8997e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate normalized rows of probabilities\n",
    "P = (N+1).float() # model smoothing to prevent log(0)=-inf\n",
    "P /= P.sum(1, keepdim=True) # https://pytorch.org/docs/stable/notes/broadcasting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccc516-db23-4159-bf5c-04f173f36c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        #p = torch.ones(27) / 27.0 # simulate a totally untrained model\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "        \n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15af639-fe53-4c6f-afd8-aa81d90da0ef",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\n",
    "\n",
    "The log likelihood is commonly used because multiplying the probabilities together gives a very small number. Since its range is [-$\\infty$, 0], we want the negative log likelihood so our loss function gets _bigger_ the worse the probabilities are. We also take the average negative log likelihood by dividing by the count of the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16a30c-0fd7-4e36-9a90-a0c1a03eec90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the average negative log likelihood\n",
    "\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob) # if the probability is 0, we get -inf which is not good, so we bias all counts to 1 above\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        #print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
    "        \n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}') # loss function (average negative log likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864cbcd-d204-41c1-ad49-2ff2caacf234",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2: The Neural Network Approach\n",
    "\n",
    "I doesn't make sense to feed integers into neurons because (for example) the tanh activation function limits the output to (-1,1). We use one-hot encoding instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85f251-72f8-4488-b105-64179fa86462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the training set of bigrams (x,y)... given x, predict y\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs, chs[1:]): # build a list of bigram pairs (sequential characters)\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        print(ch1, ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        \n",
    "xs = torch.tensor(xs) # use lower-case 't'ensor so the dtype is inferred correctly\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e32248-962d-46d9-b53b-ed36578ab28b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34dd9c6-4f1e-45d7-9434-41944891faea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28313edf-a7e6-48eb-9e5d-e5a6e96a036f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode the input as one-hot arrays.\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # one_hot() outputs dtype.int64 so case to float to feed into neural net.\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2a378-94f2-480d-8ac6-7dfeb4c458fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef08fa6f-124f-40a8-8e75-95baa81797e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a simple, single layer neural net with 27 inputs\n",
    "# Neuron: w*x\n",
    "# We are going to interpret the output as log-counts that we exponentiate to get the character index.\n",
    "\n",
    "# create a weight tensor by sampling randomly from the normal distribution.\n",
    "W = torch.randn(27, 27)\n",
    "xenc @ W  # matrix multiplication. shape: (5, 27) @ (27, 27) = (5, 27). This is the array of the neuron output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203a80c-bd4a-433c-9878-a0b2ebc60218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decode the outputs\n",
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() # equivalent to N above\n",
    "probs = counts / counts.sum(1, keepdims=True) # normalize so the rows sum to 1 so we can compare the output to the training set.\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf829eb5-17f7-4f6b-a788-a1b1829cb7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be48f8-e728-4f12-8c40-3518ab876c5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SUMMARY\n",
    "\n",
    "**Softmax**:\n",
    "\n",
    "Exponentiating logits and then normalizing them is a very common output decoding called softmax. We can interpret the softmax'd output as a probability distribution.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1.3 \\\\\n",
    "5.1 \\\\\n",
    "2.2 \\\\\n",
    "0.7 \\\\\n",
    "1.1\n",
    "\\end{bmatrix} \\Rightarrow \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^z_j} \\Rightarrow\n",
    "\\begin{bmatrix}\n",
    "0.02 \\\\\n",
    "0.90 \\\\\n",
    "0.05 \\\\\n",
    "0.01 \\\\\n",
    "0.02\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff2861-7256-4630-9d5a-4da3057ff90e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf13502-4e96-4f49-800a-296d05025199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29467ecf-9f44-4ec4-94bf-736fdcfab707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec5df8-1250-4621-875f-5c468bb2d4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# btw: the last 2 lines here are together called the 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d9e1e-52f7-4267-bcfe-c0841fe7f2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b2363-e4e0-494b-bcb1-5ef698f5efd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlls = torch.zeros(5) # size of our input set\n",
    "for i in range(5):\n",
    "    # i-th bigram\n",
    "    x = xs[i].item() # input character index\n",
    "    y = ys[i].item() # label character index\n",
    "    print('---------')\n",
    "    print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indices {x},{y})')\n",
    "    print('input to neural net:', x)\n",
    "    print('output probabilities from the neural net:', probs[i])\n",
    "    print('label (actual next character):', y)\n",
    "    p = probs[i, y]\n",
    "    print('probability assigned by the net to the correct character:', p.item())\n",
    "    logp = torch.log(p)\n",
    "    print('log likelihood:', logp.item());\n",
    "    nll = -logp\n",
    "    print('negative log likelihood:', nll.item())\n",
    "    nlls[i] = nll\n",
    "    \n",
    "print('========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784f0bd-13aa-4cf6-826a-74faecb068d5",
   "metadata": {},
   "source": [
    "## Optimization + Full Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51fd85-1b65-40f0-a139-7f7b1840b94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the training set of bigrams (x,y)... given x, predict y\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs, chs[1:]): # build a list of bigram pairs (sequential characters)\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        \n",
    "xs = torch.tensor(xs) # use lower-case 't'ensor so the dtype is inferred correctly\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645885ec-27b4-4a6a-b25d-e4a1b0bf1b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add regularization loss (aka smoothing). Like adding a spring force pushing W to 0 (see below)\n",
    "(W**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c13e85-ce5f-47d1-bb37-6ec869c80900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gradient decent\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    \n",
    "    # loss function (softmax)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    loss += 0.01 * (W**2).mean() # regularization loss\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass (gradient decent)\n",
    "    W.grad = None # efficient way to set gradients to 0\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    W.data += -50 * W.grad # negative sign to reduce the loss; not maximize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69eed9-aa24-44d9-9632-3c6c650714f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# finally, sample from the network model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # -------\n",
    "        # BEFORE:\n",
    "        # p = P[ix]\n",
    "        # -------\n",
    "        # NOW:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W # super-simple linear network layer\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        # ------\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "        \n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c20fc7c-310c-4fad-b4ba-10b314cb498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE:\n",
    "junide.\n",
    "janasah.\n",
    "p.\n",
    "cony.\n",
    "a."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
