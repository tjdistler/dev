{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae426c8-91a2-477c-99d4-da5f0e027d2e",
   "metadata": {},
   "source": [
    "# Building makemore Part 2: MLP\n",
    "\n",
    "[Andrej Karpathy](https://karpathy.ai/)\n",
    "\n",
    "[YouTube video link](https://youtu.be/TCH_1BHY58I?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n",
    "\n",
    "> We implement a multilayer perceptron (MLP) character-level language model. In this video we also introduce many basics of machine learning (e.g. model training, learning rate tuning, hyperparameters, evaluation, train/dev/test splits, under/overfitting, etc.).\n",
    "\n",
    "https://github.com/karpathy/makemore\n",
    "\n",
    "Paper: [A Neural Probabilistic Language Model - Bengio, et al](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "\n",
    "Requires the training file: `names.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29543b32-65ff-44c1-b09d-9bb50bf80cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run ONCE to update any new kernel instance.\n",
    "# You MUST restart the kernel after updating.\n",
    "!pip install --upgrade pip\n",
    "!pip install graphviz\n",
    "!apt-get update\n",
    "!apt-get install -y graphviz\n",
    "!pip install torch\n",
    "print('Complete! You\\'re good-to-go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15a409-2592-426e-b257-ec75f528910e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2adb47-ea35-4c40-89f6-4fdd633c01c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in all the words from the training set\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04393499-2592-4aed-b85b-31c333b5f879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc67b6-4c4f-4dc9-9060-5b1696057dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993705f4-6484-4708-a79b-2ff24c93c72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "    \n",
    "    #print(w)\n",
    "    context = [0] * block_size # build out padded starting context (\"...\")\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2035238-dcfc-4f36-9fac-40b96ea1a147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d1292-3d26-46ef-bd49-36751f1ae3fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "def build_dataset(words):\n",
    "    block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "\n",
    "        #print(w)\n",
    "        context = [0] * block_size # build out padded starting context (\"...\")\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# split data into 3 sets\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words)) # 80%\n",
    "n2 = int(0.9*len(words)) # 90%\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])     # training set\n",
    "Xdev, Ydev = build_dataset(words[n1:n2]) # dev/validation set\n",
    "Xte, Yte = build_dataset(words[n2:])     # test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c49b97-9651-4b84-9bdb-a8ae53eb7a62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build the 1st (input) layer of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de422b-cdbf-4aca-8cd6-a6b29b69faa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2)) # each 27 characters will have a 2D embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8151cc-8c37-42a4-84fb-3140b2fdc7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2 ways to access the row vector in C for index 5\n",
    "# The one-hot tensor: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# Matrix multiplying by C effectively plucks out the 5th row of C.\n",
    "C[5] # or...\n",
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C\n",
    "\n",
    "# also we can access multiple rows with a list\n",
    "C[[5,6,7]]\n",
    "# or a tensor (repetition is also supported)\n",
    "C[torch.tensor([5,6,7,7,7])]\n",
    "\n",
    "# also supported multidimensional tensors\n",
    "C[X] # X.shape from above is [32, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583780e4-6fe2-4ff8-b75f-e31a121ff1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using all this, build our embedding for the first layer of the network\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b81332-4a38-4eaf-9039-5a32f196b6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf0338-ffef-4561-9dab-b6cbd4df18c6",
   "metadata": {},
   "source": [
    "## Build the hidden layer of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c58cd-395e-4a8d-910c-debe1df073cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100)) # context.size (i.e. inputs) * embedding-dimensions = 3*2 = 6. 100 is the size of the hidden layer\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3a1b3-4bdf-43db-9bcf-4c9d12a495fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Doesn't \"just work\":\n",
    "# emb @ W1 + b1 ---> \"RuntimeError: mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)\"\n",
    "\n",
    "# what we need to do is concatenate the 3 input dimensions of the embedding (shape = [32, 3, 2])\n",
    "# grab the [32, 2] tensor for each of the 3 inputs\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], dim=1) # <-- block_size is hardcoded to 3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bbd5c5-d313-41bd-8517-1675cc1b2c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a more general way to do the same thing (concatenate across dimension 1)\n",
    "torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01bb0a-a0c1-48f4-887f-f2f32266391b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploring PyTorch Internals\n",
    "\n",
    "a.k.a. An even better (more efficient) way to do this concatenation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb56a0a-8017-4379-9826-d0f1c3157582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# an even better (more efficient) way to do this concatenation...\n",
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828fe7da-9485-48e0-8a6c-988987e0c9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac069e4-a659-4320-9b24-8846ab2f0422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view() is extremely efficient\n",
    "a.view(2,9)\n",
    "a.view(3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921174ca-35e9-4c1a-ab11-badf0f2c5035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# internally, a tensor is always stored as a 1D array, with offsets, strides, etc dictating access.\n",
    "a.untyped_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ca6b9-2a7a-4dc8-af38-994c70d9d22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MOST EFFICIENT concatenation using view()\n",
    "emb.view(32, 6)\n",
    "\n",
    "# emb.view(32, 6) == torch.cat(torch.unbind(emb, 1), 1) # <--- prove they are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be490287-f959-4b6e-bba7-1cea39bafcce",
   "metadata": {},
   "source": [
    "### The \"real\" hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ef929-fdde-4c0f-9dd8-875d3e4c8eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # pytorch will derive the shape when we pass -1 to make things for general\n",
    "\n",
    "# Note: we have to be careful w/ the \"+ b1\" addition and broadcasting\n",
    "#  it works because the broadcasting shifts the 1D row size of b (b.shape = [100]) to the right:\n",
    "#  32, 100 <-- result of emb @ W1\n",
    "#   1, 100 <-- b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f41545-c68a-47f6-8919-e29786daf6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h.shape # (32, 100)... gives 100 activations for each of our embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b771c-c8a8-4458-b8c7-078846e27d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9f594-8491-4253-9381-ebea627e9d3b",
   "metadata": {},
   "source": [
    "## Build the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71621cf2-99dd-45ef-bff7-1c95a9540a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27)) # inputs from hidden layer -> 27 outputs\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496d597-9438-4f54-a4c0-a591a441b547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5169d-9164-4523-b6ba-73edcc2594be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed36fe-ba40-4a4e-b4c1-bfc48fad5bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2c6e6-5759-4fe6-af62-b4ca2c5bdbe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9bf71-a294-42f0-af6f-3c9f1e98b4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c7c4f-48a7-45e8-adeb-67cbe803d7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf35e43-80ca-44bc-a44a-cf8d6d1aac92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7ec9e-d90e-4f16-938a-d3c94439ab62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867daaa7-f8c4-4872-aaf1-75d9acd9b5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob[torch.arange(32), Y] # look at the predicited probabilities for each of the training set expected values (Y). Ideally, they would all be 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf755c7-7d2b-4fcd-852b-7307f10b4eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# negative log likelihood\n",
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f48b3-e788-436b-a2cc-385ce56fdde4",
   "metadata": {},
   "source": [
    "## Making it all respectable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574f8d6-bb49-443b-8cb5-a2073b3bd570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.shape, Y.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392108b1-8b0e-47d6-875d-632d4dada8f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g) # simple linear input layer\n",
    "W1 = torch.randn((6, 100), generator=g) # hidden layer\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g) # output layer\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbeba5-1fb4-4e5b-9515-eb45d7fec6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0bdae-5b69-421d-8aca-fade3823246e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Side-tangent about cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0518a-82e8-4c39-8276-e488102d9578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb = C[X] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "\n",
    "# Everything that follows is just classification so can use PyTorch cross_entropy()\n",
    "#  counts = logits.exp()\n",
    "#  prob = counts / counts.sum(1, keepdims=True)\n",
    "#  loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss = F.cross_entropy(logits, Y) # <-- more efficient (no intermediate tensors, fused kernels simplify backward pass)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c385f4-ee96-4459-ba57-482583f8b8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# an example of why cross_entropy() is more numerically well-behaved\n",
    "logits = torch.tensor([-100, -3, 0, 100])\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563ef42-8a51-466c-b68b-1cdf2e23b7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb0fff-0fdd-4995-9e9e-2229e2da3013",
   "metadata": {},
   "source": [
    "## Let's train for real... or \"back to the respectible part\" :)\n",
    "\n",
    "Note 1: Larger models with 100,000's of parameters can easily over-fit the data. You will see this when your loss is very low for the training set, but high for the \"held back\" test set.\n",
    "\n",
    "Note 2: You are only allowed to test on the test set a few times, otherwise you risk training on the test set also.\n",
    "\n",
    "### Data Splits\n",
    "- Training set: 80%\n",
    "- Dev/validation set: 10% (used to determine hyperparameters)\n",
    "- Test set: 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a138ab-df82-4629-9611-24fb3ce3e69d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xtr.shape, Ytr.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f49c2-1feb-4bf9-9f24-6944b8db2e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "#C = torch.randn((27, 2), generator=g) # simple linear input layer\n",
    "#W1 = torch.randn((6, 100), generator=g) # hidden layer\n",
    "#b1 = torch.randn(100, generator=g)\n",
    "#W2 = torch.randn((100, 27), generator=g) # output layer\n",
    "\n",
    "# == Let's increase the size of the embeddings and hidden layer\n",
    "C = torch.randn((27, 10), generator=g)\n",
    "W1 = torch.randn((30, 200), generator=g)\n",
    "b1 = torch.randn(200, generator=g)\n",
    "W2 = torch.randn((200, 27), generator=g)\n",
    "\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287761d-58a6-4a65-ac25-2ce6fa2f3123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1b5b2-54e1-4702-a58e-0240a2df99a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3fbe05-67bf-43b2-bcd5-700caf7f7ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can create a 1D tensor of different learning rates to test for the best value\n",
    "lre = torch.linspace(-3, 0, 1000) # creates exponents from [-3,0] in 1000 steps\n",
    "lrs = 10**lre\n",
    "\n",
    "lri = []   # learning rate exponent index\n",
    "lossi = [] # loss at the exponent index\n",
    "stepi = [] # training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d3aea-9345-4f58-af0d-75ad44792a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "        \n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (64,)) # batch size: 32. We may want to increase if training loss \"noise\" per step is too high\n",
    "    \n",
    "    # forward pass\n",
    "    emb = C[Xtr[ix]]\n",
    "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    #print(loss.item())\n",
    "\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    #lr = lrs[i]\n",
    "    #lr = 0.1 # 10**-1.0\n",
    "    #lr = 0.01 # learning rate decay in later training stages\n",
    "    lr = 0.1 if i < 100000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # track stats\n",
    "    #lri.append(lre[i])\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0e033-236f-4def-bfae-f3ab8bea892b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot log loss\n",
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f674627-81bf-4eda-b3f2-7663ed99f1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graph the learning rate exponents against the loss to find the optimal learning rate (answer: -1.0)\n",
    "plt.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dccc80-879a-443a-aeb1-28cbde7674f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the loss across the test training set\n",
    "emb = C[Xtr]\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60378125-fe24-4221-8de5-3d3e184f47ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the loss across the dev training set\n",
    "emb = C[Xdev]\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd652859-6c57-44d9-abc9-ff00499ba536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha='center', va='center', color='white')\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ea865-1ae8-4318-bff1-27e34078fe23",
   "metadata": {},
   "source": [
    "## Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc1892-d393-42f3-82bc-6af4b1898280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # init with all \"...\"\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "        \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2cc5a3-3520-43ab-8296-652080533380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
